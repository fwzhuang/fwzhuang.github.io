---
layout: post
title: 机器学习-回归!
categories: ML
tags: [algorithm, ml]
comments: true
---

回归的目的是预测数值型的目标值，最直接的方式就是找到回归方程，那么就可以通过回归方程得到任意预测点的目标值。
<!--more-->

### 线性回归

说到回归，一般是指线性回归，线性回归是指可以通过将输出项分别乘以一些系数，再将结果之和作为输出。这种具有线性相关关系的方程，就是我们所说的线性回归方程。

#### 表现形式
***
* 单个输入

	$$y=ax+b$$

*  多个输入

$$h_\theta(x) =  \sum_{i=0}^n \theta_ix_i = \theta^T x $$

***

#### 损失函数

为了得到这个回归方程，我们需要找到一组最优的权重/系数$$[\theta_0, \theta_1, .... , \theta_n]=\theta$$。 那么，怎么衡量“最优”呢，那就是通过损失函数来衡量。

* 定义损失函数

$$J(\theta_0, \theta_1,...,\theta_n) = \frac{1}{2m} \sum_{i=1}^m(h_\theta x^i - y^i)^2$$

通过最小化损失函数，来得到最优的权重。为了最快得到这种权重，一般通过对损失函数进行梯度下降法进行搜索，以便较快得到损失函数的最小值。

####  梯度下降法

* 梯度下降法流程：

1）首先对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。

2）改变θ的值，使得J(θ)按梯度下降的方向进行减少。

3） 变化公式

$$ \theta = \theta - \alpha \frac {d} {d\theta} J(\theta)$$

其中a就是步长，即所谓的学习率。

####  过拟合与欠拟合

在求解回归方程中，可能会出现过拟合或欠拟合的情况。

* 欠拟合：如果样本数据太少，或者得到的特征太少，从而导致预测的目标值不准确，这种情形属于欠拟合，一般是由于样本数据信息的匮乏而导致的。
* 过拟合：如果我们有特别多的特征，我们的假设曲线以原始的训练样本数据拟合得非常好，但丧失了一般性，从而导致对新给的特预测样本，预测效果差。

#### 正则化

解决过拟合问题，一般采用正则化。所谓的正则化，是指在损失函数中添加 权重/系数作为约束项，从而降低过拟的可能性。

* 正则化

$$J(\theta_0, \theta_1,...,\theta_n) = \frac{1}{2m} [\sum_{i=1}^m(h_\theta x^i - y^i)^2 + \lambda\sum_{j=1}^n \theta_j^2]$$

其中最后项中，$$\theta$$是平方项，称为L2正则化，如果是一次的，称为L1正则化。


 



